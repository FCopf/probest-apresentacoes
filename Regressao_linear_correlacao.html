<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Regressão linear simples e correlação</title>
    <meta charset="utf-8" />
    <meta name="author" content="Instituto de Ciências do Mar - UNIFESP" />
    <script src="Regressao_linear_correlacao_files/header-attrs-2.8/header-attrs.js"></script>
    <script src="Regressao_linear_correlacao_files/htmlwidgets-1.5.3/htmlwidgets.js"></script>
    <script src="Regressao_linear_correlacao_files/jquery-3.5.1/jquery.min.js"></script>
    <link href="Regressao_linear_correlacao_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
    <script src="Regressao_linear_correlacao_files/datatables-binding-0.18/datatables.js"></script>
    <link href="Regressao_linear_correlacao_files/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="Regressao_linear_correlacao_files/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="Regressao_linear_correlacao_files/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
    <link href="Regressao_linear_correlacao_files/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
    <script src="Regressao_linear_correlacao_files/crosstalk-1.1.1/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="xaringan-themer_uso.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Regressão linear simples e correlação
## Fabio Cop
### Instituto de Ciências do Mar - UNIFESP
### 05 junho, 2021

---




&lt;style type="text/css"&gt;
.fundo {
  padding: 0 1em 0 1em;
  margin: 0;
  background-image: url(img/borda.png);
  background-size: 100%;
  background-position: 1% 1%;
  }

.espaco1 {line-height: 1.5em;}
.espaco2 {line-height: 1.1em;}
.textsize{font-size: 0.7rem}
.textsizehist{font-size: 0.95rem}

&lt;/style&gt;


---
class: fundo, espaco1, textsizehist

## Um  pouco de história

--

+ &lt;span&gt;&lt;img src="img/gauss_name.jpg" alt="Smiley face" style="float:right;height:120px;"&gt;
A primeira solução para o problema da regressão (relacionar uma variável resposta `\(Y\)` a uma variável preditora `\(X\)`) foi o &lt;b&gt;Método dos Mínimos Quadrados (MMQ)&lt;/b&gt;, publicado por por Gauss (1777 – 1855) em 1809, embora haja relatos históricos de que Gauss pensou e resolveu o problema quando tinha apenas 11 anos. Gauss aplicou o método obter predições sobre as órbitas dos corpos ao redor do Sol a partir de observações astronômicas. &lt;/span&gt;

--

+ &lt;span&gt;&lt;img src="img/galton_name.jpg" alt="Smiley face" style="float:right;height:110px;"&gt;
O termo &lt;b&gt;regressão&lt;/b&gt; foi empregado por Francis Galton em 1866, um dos pais da Biometria e primo de &lt;i&gt;Charles Darwin&lt;/i&gt;, no séc. XIX, para descrever o fenômeno biológico onde a altura dos descendentes de pais altos tende a regressar em direção à média. Desta forma, pais muito altos tenderiam a ter descendentes mais baixos que eles próprios e vice versa. A altura dos descendentes tenderia portanto a **regressar** à média da população. &lt;/span&gt;

--

+ &lt;span&gt;&lt;img src="img/pearson_name.jpg" alt="Smiley face" style="float:right;height:115px;"&gt;
Para Galton a regressão tinha apenas um significado biológico, mas suas idéias foram estendidas por Udny Yule e Karl Pearson para um contexto estatístico mais geral. Na formulação de Yule e Pearson, assume-se que a distribuição conjunta da variável resposta e da variável preditora `\(f(Y,X)\)` é Gaussiana (Normal), o que confunde os conceitos de regressão e correlação.&lt;/span&gt;

--

+ &lt;span&gt;&lt;img src="img/fisher_name.jpg" alt="Smiley face" style="float:right;height:110px;"&gt;
Esta suposição foi modificada por R. A. Fisher em 1922 e 1925. Fisher assumiu que a distribuição condicional da variável resposta `\(f(Y|X)\)` é Gaussiana, mas a conjunta não precisa ser. Esta solução é mais próxima daquela formulada por Gauss. Fisher desenvolveu também o método da &lt;b&gt;Máxima Verossimilhança (MV)&lt;/b&gt;. Para uma variável em que `\(f(Y|X)\)` é Gaussiana, a solução pelo &lt;b&gt;MMQ&lt;/b&gt; e pela &lt;b&gt;MV&lt;/b&gt; convergem.&lt;/span&gt;

---

class: fundo, textsize, textsizehist

## Conteúdo da Aula

1. Introdução

 1.1. Descrevendo relações funcionais
 
 1.2. Predições sobre fenômenos ambientais 
  
 1.3. Estrutura geral do modelo de regressão
  
2. Compreendendo o modelo

 2.1. O modelo matemático
  
 2.2. Os dados e o gráfico de dispersão
  
 2.3. O modelo estatístico
  
 2.4. Estimativa dos parâmetros: Método dos mínimos quadrados
 
 2.5. Variâncias e Covariâncias
   
3. Teste de hipóteses: coeficiente de inclinação
  
4. Pressupostos da regressão linear
 
5. Coeficiente de correlação linear de Pearson


---

class: fundo, textsize

### 1. Descrevendo relações funcionais

O Serviço Florestal americano estabeleceu a Floresta Experimental de [**Hubbard Brook (HBEF)**](https://hubbardbrook.org/)  em 1955 como um centro de pesquisa hidrológica. Um serviço ecossistêmico óbvio das bacias hidrográficas nesta região é o fornecimento hídrico. Podemos supor que o volume de água anual que uma bacia pode fornecer tem relação com o volume de chuva.


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Descrevendo relações funcionais

O Serviço Florestal americano estabeleceu a Floresta Experimental de [**Hubbard Brook (HBEF)**](https://hubbardbrook.org/)  em 1955 como um centro de pesquisa hidrológica. Um serviço ecossistêmico óbvio das bacias hidrográficas nesta região é o fornecimento hídrico. Podemos supor que o volume de água anual que uma bacia pode fornecer tem relação com o volume de chuva.


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Predições sobre fenômenos ambientais

O Serviço Florestal americano estabeleceu a Floresta Experimental de [**Hubbard Brook (HBEF)**](https://hubbardbrook.org/)  em 1955 como um centro de pesquisa hidrológica. Um serviço ecossistêmico óbvio das bacias hidrográficas nesta região é o fornecimento hídrico. Podemos supor que o volume de água anual que uma bacia pode fornecer tem relação com o volume de chuva.


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Predições sobre fenômenos ambientais

#### Taxa de fotossíntese em folhas do mangue-vermelho (*Rhizophora mangle*)

`$$Y = \frac{k \times X}{D + X}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-5-1.png" width="541" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Seja uma variável aleatória `\(Y\)` com distribuição normal proveniente de um *experimento aleatório*.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;


---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Seja uma variável aleatória `\(Y\)` com distribuição normal proveniente de um *experimento aleatório*.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Para cada observação `\(y_i\)` é conhecida também uma informação sobre `\(x_i\)`.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Para cada observação `\(y_i\)` é conhecida também uma informação sobre `\(x_i\)`.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-9-1.gif" style="display: block; margin: auto;" /&gt;

---


class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Para cada observação `\(y_i\)` é conhecida também uma informação sobre `\(x_i\)`.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Para cada observação `\(y_i\)` é conhecida também uma informação sobre `\(x_i\)`.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

Para cada observação `\(y_i\)` é conhecida também uma informação sobre `\(x_i\)`.

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo, textsize

### 1. Estrutura geral do modelo de regressão

.pull-left[

1 - As observações em `\(Y\)` e `\(X\)` compõem um par `\((y_i, x_i)\)` de modo que:

`$$Y = \begin{bmatrix} y_1 \\ y_2 \\ \cdots \\ y_n \end{bmatrix},
X = \begin{bmatrix} x_1 \\ x_2 \\ \cdots \\ x_n \end{bmatrix}$$`

2 - `\(X\)` é determinada **experimentalmente** e **sem erros**.

3 - `\(Y\)` é uma variável aleatória normalmente distribuída, com `\(\mu_i\)` variância `\(\sigma^2\)`.

`$$Y \sim \mathcal{N}(\mu_i, \sigma^2)$$`

4 - `\(\mu_i\)` é representado por um **modelo linear** que expressa o valor esperado de `\(y_i\)` para um dado valor de `\(x_i\)`. Compõe a **parcela determinística** do modelo.

`$$E(Y|x_i) = \mu_i = \beta_0 + \beta_1x_i$$`

5 - `\(\beta_0\)` e `\(\beta_1\)` são as contantes a serem estimadas, representando o **intercepto** e o **coeficience de inclinação da reta**, repectivamente.

6 - `\(\sigma^2\)` é a **variância** de `\(Y\)` e ser estimada. `\(\sigma^2\)` é **constante** para todos os valores em `\(X\)`.
]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo, textsize

### 2. O modelo matemático

.pull-left[

1. `\(Y\)`: variável resposta (dependente);

2. `\(X\)`: variável preditora (**in**dependente);

`$$E(Y|x_i) = \beta_0 + \beta_1x_i$$`
3. **Parâmetros do mdelo**

`\(\beta_0\)`: Intercepto;

`\(\beta_1\)`: coeficiente de inclinação da reta (**coeficiente de regressão**);

]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 2. O modelo matemático

Se o intercepto `\(\beta_0\)` e a inclinação `\(\beta_1\)` são conhecidos, podemos **PREDIZER** qualquer valor `\(y_i\)` para um dado valor em `\(x_i\)`.

`$$E(Y|x_i) = \beta_0 + \beta_1x_i$$`


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. A tabela e o gráfico de dispersão

`$$y_i|x_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

.pull-left[


<div id="htmlwidget-7e293be7c01b4d1e0b5c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7e293be7c01b4d1e0b5c">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26"],[0.78,1.59,1.44,0.9,1.62,1.64,1.1,0.66,1.1,1.19,1.82,1.51,1.54,0.81,1.83,1.51,1.87,1.59,1.07,1.34,2.1,1.66,1.53,1.86,1.65,1.73],[0,0.01,0.04,0.06,0.07,0.09,0.12,0.13,0.15,0.29,0.33,0.45,0.45,0.51,0.52,0.58,0.65,0.68,1.09,1.18,1.26,1.72,2.07,2.14,2.21,2.56]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Diversidade<\/th>\n      <th>Vazao<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"lengthMenu":[3,5],"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>


]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 2. O modelo estatístico: reta de regressão e resíduos `\((\varepsilon_i)\)`

`$$y_i|x_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

.pull-left[

<div id="htmlwidget-4f2bc96119f020fb83b4" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-4f2bc96119f020fb83b4">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26"],[0.78,1.59,1.44,0.9,1.62,1.64,1.1,0.66,1.1,1.19,1.82,1.51,1.54,0.81,1.83,1.51,1.87,1.59,1.07,1.34,2.1,1.66,1.53,1.86,1.65,1.73],[0,0.01,0.04,0.06,0.07,0.09,0.12,0.13,0.15,0.29,0.33,0.45,0.45,0.51,0.52,0.58,0.65,0.68,1.09,1.18,1.26,1.72,2.07,2.14,2.21,2.56],[1.28,1.29,1.29,1.3,1.3,1.3,1.31,1.31,1.32,1.35,1.35,1.38,1.38,1.39,1.39,1.41,1.42,1.43,1.51,1.53,1.55,1.64,1.72,1.73,1.75,1.82],[-0.5,0.3,0.15,-0.4,0.32,0.34,-0.21,-0.65,-0.22,-0.16,0.47,0.13,0.16,-0.58,0.44,0.1,0.45,0.16,-0.44,-0.19,0.55,0.02,-0.19,0.13,-0.1,-0.09]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>$$y_i$$<\/th>\n      <th>$$x_i$$<\/th>\n      <th>$$\\hat{y}_i$$<\/th>\n      <th>$$\\varepsilon_i$$<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"lengthMenu":[3,5],"columnDefs":[{"className":"dt-right","targets":[1,2,3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>


]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 2. O modelo estatístico: reta de regressão e resíduos `\((\varepsilon_i)\)`

`$$y_i|x_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

.pull-left[

<div id="htmlwidget-7455d817246b0e0deed0" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7455d817246b0e0deed0">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26"],[0.78,1.59,1.44,0.9,1.62,1.64,1.1,0.66,1.1,1.19,1.82,1.51,1.54,0.81,1.83,1.51,1.87,1.59,1.07,1.34,2.1,1.66,1.53,1.86,1.65,1.73],[0,0.01,0.04,0.06,0.07,0.09,0.12,0.13,0.15,0.29,0.33,0.45,0.45,0.51,0.52,0.58,0.65,0.68,1.09,1.18,1.26,1.72,2.07,2.14,2.21,2.56],[1.28,1.29,1.29,1.3,1.3,1.3,1.31,1.31,1.32,1.35,1.35,1.38,1.38,1.39,1.39,1.41,1.42,1.43,1.51,1.53,1.55,1.64,1.72,1.73,1.75,1.82],[-0.5,0.3,0.15,-0.4,0.32,0.34,-0.21,-0.65,-0.22,-0.16,0.47,0.13,0.16,-0.58,0.44,0.1,0.45,0.16,-0.44,-0.19,0.55,0.02,-0.19,0.13,-0.1,-0.09]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>$$y_i$$<\/th>\n      <th>$$x_i$$<\/th>\n      <th>$$\\hat{y}_i$$<\/th>\n      <th>$$\\varepsilon_i$$<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":5,"lengthMenu":[3,5],"columnDefs":[{"className":"dt-right","targets":[1,2,3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>


]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 2. O modelo estatístico: reta de regressão e resíduos `\((\varepsilon_i)\)`

`$$y_i|x_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

.pull-left[

- `\(y_i\)`: variável resposta - `\(i\)`: `\(1 \cdots n\)`;

- `\(x_i\)`: variável preditora - `\(i\)`: `\(1 \cdots n\)`;

- `\(n\)`: tamanho da amostra;

- `\(\beta_0\)`: intercepto;

- `\(\beta_1\)`: coeficiente inclinação da reta;

- `\(\varepsilon_i\)`: resíduo - responsável pela variação de `\(y_i\)` em torno do valor **predito** `\((\hat{y}_i)\)` pela reta de regressão.

]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-22-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 2. O modelo estatístico: reta de regressão e resíduos `\((\varepsilon_i)\)`

`$$y_i|x_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

.pull-left[

- `\(y_i\)`: variável resposta - `\(i\)`: `\(1 \cdots n\)`;

- `\(x_i\)`: variável preditora - `\(i\)`: `\(1 \cdots n\)`;

- `\(n\)`: tamanho da amostra;

- `\(\beta_0\)`: intercepto;

- `\(\beta_1\)`: coeficiente inclinação da reta;

- `\(\varepsilon_i\)`: resíduo - responsável pela variação de `\(y_i\)` em torno do valor **predito** `\((\hat{y}_i)\)` pela reta de regressão.

##### O resíduo associado a cada observação diminui ou aumenta à medida que o pontos está mais próximo ou distante da reta de regressão.


]

.pull-right[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 2. Estimativa dos parâmetros

`$$y_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

.pull-left[

#### Parte determinística: `\(\beta_0\)` e `\(\beta_1\)`

`$$\beta_0 + \beta_1x_i$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-24-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

#### Parte estocástica: `\(\sigma^2\)`

`$$\varepsilon_i \sim \mathcal{N}(0, \sigma^2)$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-25-1.png" style="display: block; margin: auto;" /&gt;

]

---

class: fundo

### 2. Estimativa dos parâmetros

`$$y_i = \beta_0 + \beta_1x_i + \varepsilon_i$$`

#### Como estimar os parâmetros de um modelo de regressão?

1. Método dos Mínimos Quadrados (MMQ)

2. Estimador de Máxima Verossimilhança (EMV)

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-26-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-27-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-28-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-29-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

#### Soma dos quadrados dos resíduos `\((SQ_{Res})\)` 


.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-30-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-rigth[

`$$SQ_{Res} = \sum_{i=1}^{n}\varepsilon_i^2 = \sum_{i=1}^{n}(y_i - \hat{y_i})^2$$`

O método dos mínimos quadrados consiste em encontrar a reta que **MINIMIZA** o somatório dos quadrados dos resíduos.

]

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

#### Soma dos quadrados dos resíduos `\((SQ_{Res})\)` 


.pull-left[


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-31-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-rigth[

`$$SQ_{Res} = \sum_{i=1}^{n}\varepsilon_i^2 = \sum_{i=1}^{n}(y_i - \hat{y_i})^2$$`

O método dos mínimos quadrados consiste em encontrar a reta que **MINIMIZA** o somatório dos quadrados dos resíduos.

]

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

#### Soma dos quadrados dos resíduos `\((SQ_{Res})\)` 

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-32-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-rigth[

`$$SQ_{Res} = \sum_{i=1}^{n}\varepsilon_i^2 = \sum_{i=1}^{n}(y_i - \hat{y_i})^2$$`

O método dos mínimos quadrados consiste em encontrar a reta que **MINIMIZA** o somatório dos quadrados dos resíduos.

]

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

#### O método dos mínimos quadrados consiste em encontrar a reta que **MINIMIZA** o somatório dos quadrados dos resíduos.

`$$SQ_{Res} = \sum_{i=1}^{n}\varepsilon_i^2 = \sum_{i=1}^{n}(y_i - \hat{y_i})^2$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-33-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Estimativa dos parâmetros: *O Método dos Mínimos Quadrados (MMQ)*

#### ---&gt; *Estime* `\(\hat{\beta}_0\)` e `\(\hat{\beta}_1\)` que minimize a quantia:

`$$\sum_{i=1}^{n}(y_i - \hat{y_i})^2 = \sum_{i=1}^{n}(y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-34-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Variâncias e Covariâncias




.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-36-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

]

---

class: fundo

### 2. Variâncias e Covariâncias

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-37-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

]

---

class: fundo

### 2. Variâncias e Covariâncias

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-38-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

]

---

class: fundo

### 2. Variâncias e Covariâncias

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-39-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

]

---

class: fundo

### 2. Variâncias e Covariâncias

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-40-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

#### Soma dos Quadrados de `\(Y\)`

`$$SQ_Y = \sum_{i = 1}^{n} (y_i - \overline{y})^2 = \sum_{i = 1}^{n} (y_i - \overline{y}) (y_i - \overline{y})$$`

#### Variância amostral de `\(Y\)`

`$$s^{2}_{Y} = \frac{\sum_{i = 1}^{n} (y_i - \overline{y})^2}{n-1}$$`

]

---

class: fundo

### 2. Variâncias e Covariâncias

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-41-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

#### Soma dos Quadrados de `\(X\)`

`$$SQ_X = \sum_{i = 1}^{n} (x_i - \overline{x})^2 = \sum_{i = 1}^{n} (x_i - \overline{x}) (x_i - \overline{x})$$`

#### Variância amostral de `\(X\)`

`$$s^{2}_{X} = \frac{\sum_{i = 1}^{n} (x_i - \overline{x})^2}{n-1}$$`

]

---

class: fundo

### 2. Variâncias e Covariâncias

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-42-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

#### Soma dos produtos cruzados de `\(Y\)` e `\(X\)`

`$$SQ_{YX} = \sum_{i = 1}^{n} (y_i - \overline{y}) (x_i - \overline{x})$$`

#### Covariância amostral entre `\(Y\)` e `\(X\)`

`$$s_{YX} = \frac{\sum_{i = 1}^{n} (y_i - \overline{y}) (x_i - \overline{x})}{n-1}$$`

]

---

class: fundo

### 2. Variâncias e Covariâncias

#### A covariância pode ser **NEGATIVA**

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-43-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Quando:

`\((y_i - \overline{y}) &gt; 0\)`; `\((x_i - \overline{x}) &lt; 0\)`

ou

`\((y_i - \overline{y}) &lt; 0\)`; `\((x_i - \overline{x}) &gt; 0\)`

de modo que:

`\(s_{YX} = \frac{\sum_{i = 1}^{n} (y_i - \overline{y}) (x_i - \overline{x})}{n-1} &lt; 0\)`

]

---

class: fundo

### 2. Variâncias e Covariâncias

#### A covariância pode ser **POSITIVA**

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-44-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Quando:

`\((y_i - \overline{y}) &gt; 0\)`; `\((x_i - \overline{x}) &gt; 0\)`

ou

`\((y_i - \overline{y}) &lt; 0\)`; `\((x_i - \overline{x}) &lt; 0\)`

de modo que:

`\(s_{YX} = \frac{\sum_{i = 1}^{n} (y_i - \overline{y}) (x_i - \overline{x})}{n-1} &gt; 0\)`

]

---

class: fundo

### 2. Variâncias e Covariâncias

#### A covariância pode ser **NULA**

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-45-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Quando:

`\((y_i - \overline{y}) \approx 0\)`; `\((x_i - \overline{x}) \approx 0\)`

ou

`\((y_i - \overline{y}) \approx 0\)`; `\((x_i - \overline{x}) \approx 0\)`

de modo que:

`\(s_{YX} = \frac{\sum_{i = 1}^{n} (y_i - \overline{y}) (x_i - \overline{x})}{n-1} \approx 0\)`

]

---

class: fundo

### 2. Variâncias e Covariâncias

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-46-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Variâncias e Covariâncias: *estimando `\(\beta_1\)`*

#### `$$\hat{\beta}_1 = \frac{SQ_{YX}}{SQ_X} = \frac{s_{XY}}{s^2_X}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-47-1.png" style="display: block; margin: auto;" /&gt;


---

class: fundo

### 2. Variâncias e Covariâncias: *estimando `\(\beta_0\)`*

#### `$$\overline{y} = \hat{\beta}_0 + \hat{\beta}_1 \overline{x}$$`

#### `$$\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}$$`


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-48-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 2. Variâncias e Covariâncias: *estimando `\(\sigma^2\)`*

#### `$$y_i = \hat{\beta}_0 + \hat{\beta}_1 x_i + \varepsilon_i$$`

.pull-left[
&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-49-1.png" style="display: block; margin: auto;" /&gt;
]

.pull-right[

#### O Quadrado Médio do Resíduo `\((QM_{Res})\)`

`$$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$`

`$$\hat{\sigma}^2 = QM_{Res} = \frac{SQ_{Res}}{n-2}$$`


]


---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

.pull-left[

#### Hipótese nula

#### `$$H_0: \beta_1 = 0$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-50-1.png" style="display: block; margin: auto;" /&gt;

`$$y_i = \beta_0 + \varepsilon_i$$`
]

.pull-right[

#### Hipótese alternativa

#### `$$H_1: \beta_1 \ne 0$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-51-1.png" style="display: block; margin: auto;" /&gt;

`$$y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$$`
]

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(H_0\)` pode ser testada por meio do teste `\(t\)` para o estimador `\(\hat{\beta}_1\)`

.pull-left[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-52-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

`\(t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}\)`

Erro padrão de `\(\hat{\beta}_1\)`

`\(s_{\hat{\beta}_1} = \sqrt{\frac{\hat{\sigma}^2}{SQ_{X}}}\)`

]


---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende da **magnitude de `\(\hat{\beta_1}\)`**

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-53-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende da **magnitude de `\(\hat{\beta_1}\)`**

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-54-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende da **magnitude de `\(\hat{\beta_1}\)`**

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-55-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende da **variância residual** - `\(s_{\hat{\beta_1}} = \sqrt{\frac{\hat{\sigma}^2}{SQ_{X}}}\)`

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-56-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende da **variância residual** - `\(s_{\hat{\beta_1}} = \sqrt{\frac{\hat{\sigma}^2}{SQ_{X}}}\)`

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-57-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende do **tamanho da amostra** - `\(n\)`

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-58-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses para `\(\beta_1\)`

`\(t_{calculado}\)` depende do **tamanho da amostra** - `\(n\)`

`$$t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}}$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-59-1.png" style="display: block; margin: auto;" /&gt;

---

class: fundo

### 3. Teste de hipóteses: diversidade de espécies e vazão

.pull-left[



Na figura ao lado, os coeficientes de regressão foram estimados pelo MMQ em `\(\hat{\beta}_0 = 1.28\)` e `\(\hat{\beta}_1 = 0.21\)`.

O valor de `\(t\)` foi:

`\(t_{calculado} = \frac{\hat{\beta}_1- \beta_1}{s_{\hat{\beta}_1}} = \frac{0.21 - 0}{0.089} = 2.351\)`

Embora exista uma alta variabilidade ao redor da reta de regressão o valor de `\(p\)` associado a este resultado foi `\(p = 0.0273\)`, o que se interpretado ao nível de significância `\(\alpha = 0,05\)` nos leva a **rejeitar** `\(H_0\)`.

Nossa conclusão é de que **existe** uma relação crescente entre a Diversidade de espécies e a vazão dos riachos.

]

.pull-right[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-61-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 3. Teste de hipóteses: diversidade de espécies e vazão

.pull-left[


```r
rdiv &lt;- lm(Diversidade ~ Vazao, data = peixes)
summary(rdiv)
```

```
## 
## Call:
## lm(formula = Diversidade ~ Vazao, data = peixes)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65179 -0.20498  0.06043  0.26830  0.55249 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.28467    0.09508  13.512 1.03e-12 ***
## Vazao        0.20861    0.08873   2.351   0.0273 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3486 on 24 degrees of freedom
## Multiple R-squared:  0.1872,	Adjusted R-squared:  0.1533 
## F-statistic: 5.527 on 1 and 24 DF,  p-value: 0.02728
```

]

.pull-right[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-63-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 3. Teste de hipóteses: diversidade de espécies e vazão

.pull-left[


```r
rdiv &lt;- lm(Diversidade ~ Vazao, data = peixes)
summary(rdiv)
```

```
## 
## Call:
## lm(formula = Diversidade ~ Vazao, data = peixes)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65179 -0.20498  0.06043  0.26830  0.55249 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.28467    0.09508  13.512 1.03e-12 ***
## Vazao        0.20861    0.08873   2.351   0.0273 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3486 on 24 degrees of freedom
## Multiple R-squared:  0.1872,	Adjusted R-squared:  0.1533 
## F-statistic: 5.527 on 1 and 24 DF,  p-value: 0.02728
```

]

.pull-right[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-65-1.png" style="display: block; margin: auto;" /&gt;
]



---

class: fundo

### 4. Pressupostos da regressão linear

Ao realizar uma regressão linear simples, devemos assumir como verdadeiros alguns pressupostos.

.pull-left[

1. &lt;span style="color:#ed5858"&gt;O modelo linear descreve adequadamente a relação funcional entre `\(Y\)` e `\(X\)`;&lt;/span&gt;

2. Cada par de observação `\((y_i,x_i)\)` é independente dos demais;

3. A variável `\(X\)` é medida sem erros;

4. Os resíduos têm distribuição normal;

5. A variância residual `\(\sigma^2\)` é constante ao longo de `\(X\)`.
]

.pull-right[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-66-1.png" style="display: block; margin: auto;" /&gt;

]

---

class: fundo

### 4. Pressupostos da regressão linear

Ao realizar uma regressão linear simples, devemos assumir como verdadeiros alguns pressupostos.

.pull-left[

1. O modelo linear descreve adequadamente a relação funcional entre `\(Y\)` e `\(X\)`;

2. &lt;span style="color:#ed5858"&gt;Cada par de observação `\((y_i,x_i)\)` é independente dos demais;&lt;/span&gt;

3. A variável `\(X\)` é medida sem erros;

4. Os resíduos têm distribuição normal;

5. A variância residual `\(\sigma^2\)` é constante ao longo de `\(X\)`.
]

.pull-right[

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-67-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 4. Pressupostos da regressão linear

Ao realizar uma regressão linear simples, devemos assumir como verdadeiros alguns pressupostos.

.pull-left[

1. O modelo linear descreve adequadamente a relação funcional entre `\(Y\)` e `\(X\)`;

2. Cada par de observação `\((y_i,x_i)\)` é independente dos demais;

3. &lt;span style="color:#ed5858"&gt;A variável `\(X\)` é medida sem erros;&lt;/span&gt;

4. Os resíduos têm distribuição normal;

5. A variância residual `\(\sigma^2\)` é constante ao longo de `\(X\)`.
]

.pull-right[

`$$Y \sim \mathcal{N}(\mu_i, \sigma^2)$$`

`$$E(Y|x_i) = \mu_i = \beta_0 + \beta_1x_i$$`

&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-68-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 4. Pressupostos da regressão linear

Ao realizar uma regressão linear simples, devemos assumir como verdadeiros alguns pressupostos.

.pull-left[

1. O modelo linear descreve adequadamente a relação funcional entre `\(Y\)` e `\(X\)`;

2. Cada par de observação `\((y_i,x_i)\)` é independente dos demais;

3. A variável `\(X\)` é medida sem erros;

4. &lt;span style="color:#ed5858"&gt;Os resíduos têm distribuição normal;&lt;/span&gt;

5. A variância residual `\(\sigma^2\)` é constante ao longo de `\(X\)`.
]

.pull-right[

`$$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$`


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-69-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: fundo

### 4. Pressupostos da regressão linear

Ao realizar uma regressão linear simples, devemos assumir como verdadeiros alguns pressupostos.

.pull-left[

1. O modelo linear descreve adequadamente a relação funcional entre `\(Y\)` e `\(X\)`;

2. Cada par de observação `\((y_i,x_i)\)` é independente dos demais;

3. A variável `\(X\)` é medida sem erros;

4. Os resíduos têm distribuição normal;

5. &lt;span style="color:#ed5858"&gt;A variância residual `\(\sigma^2\)` é constante ao longo de `\(X\)`.&lt;/span&gt;
]

.pull-right[

`$$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$`


&lt;img src="Regressao_linear_correlacao_files/figure-html/unnamed-chunk-70-1.png" style="display: block; margin: auto;" /&gt;
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
